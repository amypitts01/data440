\documentclass[a4paper]{article}
%\usepackage{simplemargins}

%\usepackage[square]{natbib}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}

\begin{document}
\pagenumbering{gobble}

\Large
 \begin{center}
A Monte Carlo Markov Chain Technique to Reinforcement Learning
\hspace{10pt}

% Author names and affiliations
\large
Amy Pitts
\\

\hspace{10pt}

\small 
Machine Learning DATA 440 \\ 
February 9, 2019 \\
Amy.Pitts1@marist.edu\\

\end{center}

\hspace{10pt}

\normalsize

\indent This project will analyze how a Markov chain Monte Carlo
technique can be implemented in reinforcement learning. This 
underlying Bayesian technique will enable an algorithm to make 
decisions based off of state changes and probability ratios.  
I am fascinated by algorithms being able to learn based on the 
actions taken. This project is inspired by my summer REU project. 
Although that project was categorized as statistics, I argue that
the Bayesian procedure that we developed is a reinforcement 
learning algorithm.  I, however, do not want to steal or copy 
any of that work and will instead take a broader look into how a 
Bayesian procedure aided by a Markov chain Monte Carlo can be 
used in a reinforcement algorithm. \\ 
\indent My goal with this theoretical project is to look at the 
math behind the algorithms and the potential applications this 
reinforcement learning approach has.  Below are some academic 
sources I have gathered. I would also like to apply this project 
to a clustering problem. The Bayesian framework would help 
determine the location and number of clusters and error rates.  
The output would be two distribution, one being the location 
and one being the number of clusters. Coded in python, this 
algorithm theoretically could take any data and would output 
the distribution of number and location of clusters as well 
as the error rates. 



\begin{thebibliography}{9}
    %Starting at background: 
    \bibitem{Ramachandran07}
    D. Ramachandran, and E. Amir. "Bayesian inverse reinforcement 
    learning." \textit{Urbana}  vol.51 pp.1-4, 2007. 

    \bibitem{Strens00}
    M. Strens, “A Bayesian framework for reinforcement learning.” 
    \textit{ICML} pp. 943-950, 2000. 

    \bibitem{Salakhutdinov08}
    R. Salakhutdinov and A. Mnih "Bayesian probabilistic matrix factorization 
    using Markov chain Monte Carlo." \textit{In Proceedings of the 25th 
    international conference on Machine learning (ICML '08)}. 
    pp.880-887, 2008 DOI=http://dx.doi.org/10.1145/1390156.1390267

    \bibitem{Jaakkola95}
    T. Jaakkola, S. Singh, and M. Jordan "Reinforcement Learning 
    Algorithm for Partially Observable Markov Decision Problems" 
    \textit{ Advances in neural information processing systems}
    pp.345-352, 1995

    \bibitem{Jaakkola95}
    D. A. Binder "Bayesian Cluster Analysis" 
    \textit{Biometrika} no.1, vol. 65 pp. 31-38. 1978.



\end{thebibliography}

\end{document}