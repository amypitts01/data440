{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "MQNW_k6_l2Gd",
        "colab_type": "code",
        "outputId": "22fa3a3e-c287-4ec7-a350-ff20708453b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2890
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "from six.moves import range\n",
        "\n",
        "\n",
        "class CharacterTable(object):\n",
        "    \"\"\"Given a set of characters:\n",
        "    + Encode them to a one-hot integer representation\n",
        "    + Decode the one-hot or integer representation to their character output\n",
        "    + Decode a vector of probabilities to their character output\n",
        "    \"\"\"\n",
        "    def __init__(self, chars):\n",
        "        \"\"\"Initialize character table.\n",
        "        # Arguments\n",
        "            chars: Characters that can appear in the input.\n",
        "        \"\"\"\n",
        "        self.chars = sorted(set(chars))\n",
        "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
        "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
        "\n",
        "    def encode(self, C, num_rows):\n",
        "        \"\"\"One-hot encode given string C.\n",
        "        # Arguments\n",
        "            C: string, to be encoded.\n",
        "            num_rows: Number of rows in the returned one-hot encoding. This is\n",
        "                used to keep the # of rows for each data the same.\n",
        "        \"\"\"\n",
        "        x = np.zeros((num_rows, len(self.chars)))\n",
        "        for i, c in enumerate(C):\n",
        "            x[i, self.char_indices[c]] = 1\n",
        "        return x\n",
        "\n",
        "    def decode(self, x, calc_argmax=True):\n",
        "        \"\"\"Decode the given vector or 2D array to their character output.\n",
        "        # Arguments\n",
        "            x: A vector or a 2D array of probabilities or one-hot representations;\n",
        "                or a vector of character indices (used with `calc_argmax=False`).\n",
        "            calc_argmax: Whether to find the character index with maximum\n",
        "                probability, defaults to `True`.\n",
        "        \"\"\"\n",
        "        if calc_argmax:\n",
        "            x = x.argmax(axis=-1)\n",
        "        return ''.join(self.indices_char[x] for x in x)\n",
        "\n",
        "\n",
        "class colors:\n",
        "    ok = '\\033[92m'\n",
        "    fail = '\\033[91m'\n",
        "    close = '\\033[0m'\n",
        "\n",
        "# Parameters for the model and dataset.\n",
        "TRAINING_SIZE = 50000\n",
        "DIGITS = 3\n",
        "REVERSE = True\n",
        "\n",
        "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
        "# int is DIGITS.\n",
        "MAXLEN = DIGITS + 1 + DIGITS\n",
        "\n",
        "# All the numbers, plus sign and space for padding.\n",
        "chars = '0123456789+ '\n",
        "ctable = CharacterTable(chars)\n",
        "\n",
        "questions = []\n",
        "expected = []\n",
        "seen = set()\n",
        "print('Generating data...')\n",
        "while len(questions) < TRAINING_SIZE:\n",
        "    f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
        "                    for i in range(np.random.randint(1, DIGITS + 1))))\n",
        "    a, b = f(), f()\n",
        "    # Skip any addition questions we've already seen\n",
        "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
        "    key = tuple(sorted((a, b)))\n",
        "    if key in seen:\n",
        "        continue\n",
        "    seen.add(key)\n",
        "    # Pad the data with spaces such that it is always MAXLEN.\n",
        "    q = '{}+{}'.format(a, b)\n",
        "    query = q + ' ' * (MAXLEN - len(q))\n",
        "    ans = str(a + b)\n",
        "    # Answers can be of maximum size DIGITS + 1.\n",
        "    ans += ' ' * (DIGITS + 1 - len(ans))\n",
        "    if REVERSE:\n",
        "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
        "        # space used for padding.)\n",
        "        query = query[::-1]\n",
        "    questions.append(query)\n",
        "    expected.append(ans)\n",
        "print('Total addition questions:', len(questions))\n",
        "\n",
        "print('Vectorization...')\n",
        "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(questions):\n",
        "    x[i] = ctable.encode(sentence, MAXLEN)\n",
        "for i, sentence in enumerate(expected):\n",
        "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
        "\n",
        "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
        "# digits.\n",
        "indices = np.arange(len(y))\n",
        "np.random.shuffle(indices)\n",
        "x = x[indices]\n",
        "y = y[indices]\n",
        "\n",
        "# Explicitly set apart 10% for validation data that we never train over.\n",
        "split_at = len(x) - len(x) // 10\n",
        "(x_train, x_val) = x[:split_at], x[split_at:]\n",
        "(y_train, y_val) = y[:split_at], y[split_at:]\n",
        "\n",
        "print('Training Data:')\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print('Validation Data:')\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)\n",
        "\n",
        "# Try replacing GRU, or SimpleRNN.\n",
        "RNN = layers.LSTM\n",
        "HIDDEN_SIZE = 128\n",
        "BATCH_SIZE = 128\n",
        "LAYERS = 1\n",
        "\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "# \"Encode\" the input sequence using an RNN, producing an output of HIDDEN_SIZE.\n",
        "# Note: In a situation where your input sequences have a variable length,\n",
        "# use input_shape=(None, num_feature).\n",
        "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
        "# As the decoder RNN's input, repeatedly provide with the last output of\n",
        "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
        "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
        "model.add(layers.RepeatVector(DIGITS + 1))\n",
        "# The decoder RNN could be multiple layers stacked or a single layer.\n",
        "for _ in range(LAYERS):\n",
        "    # By setting return_sequences to True, return not only the last output but\n",
        "    # all the outputs so far in the form of (num_samples, timesteps,\n",
        "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
        "    # the first dimension to be the timesteps.\n",
        "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
        "\n",
        "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
        "# of the output sequence, decide which character should be chosen.\n",
        "model.add(layers.TimeDistributed(layers.Dense(len(chars), activation='softmax')))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Train the model each generation and show predictions against the validation\n",
        "# dataset.\n",
        "for iteration in range(1, 10):\n",
        "    print()\n",
        "    print('-' * 50)\n",
        "    print('Iteration', iteration)\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              epochs=1,\n",
        "              validation_data=(x_val, y_val))\n",
        "    # Select 10 samples from the validation set at random so we can visualize\n",
        "    # errors.\n",
        "    for i in range(10):\n",
        "        ind = np.random.randint(0, len(x_val))\n",
        "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
        "        preds = model.predict_classes(rowx, verbose=0)\n",
        "        q = ctable.decode(rowx[0])\n",
        "        correct = ctable.decode(rowy[0])\n",
        "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
        "        print('Q', q[::-1] if REVERSE else q, end=' ')\n",
        "        print('T', correct, end=' ')\n",
        "        if correct == guess:\n",
        "            print(colors.ok + '☑' + colors.close, end=' ')\n",
        "        else:\n",
        "            print(colors.fail + '☒' + colors.close, end=' ')\n",
        "        print(guess)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating data...\n",
            "Total addition questions: 50000\n",
            "Vectorization...\n",
            "Training Data:\n",
            "(45000, 7, 12)\n",
            "(45000, 4, 12)\n",
            "Validation Data:\n",
            "(5000, 7, 12)\n",
            "(5000, 4, 12)\n",
            "Build model...\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_5 (LSTM)                (None, 128)               72192     \n",
            "_________________________________________________________________\n",
            "repeat_vector_3 (RepeatVecto (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 4, 128)            131584    \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, 4, 12)             1548      \n",
            "=================================================================\n",
            "Total params: 205,324\n",
            "Trainable params: 205,324\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 1\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 19s 418us/step - loss: 1.8869 - acc: 0.3222 - val_loss: 1.7928 - val_acc: 0.3438\n",
            "Q 19+267  T 286  \u001b[91m☒\u001b[0m 102 \n",
            "Q 409+82  T 491  \u001b[91m☒\u001b[0m 103 \n",
            "Q 3+524   T 527  \u001b[91m☒\u001b[0m 43  \n",
            "Q 97+657  T 754  \u001b[91m☒\u001b[0m 100 \n",
            "Q 264+32  T 296  \u001b[91m☒\u001b[0m 222 \n",
            "Q 9+419   T 428  \u001b[91m☒\u001b[0m 100 \n",
            "Q 501+78  T 579  \u001b[91m☒\u001b[0m 103 \n",
            "Q 57+60   T 117  \u001b[91m☒\u001b[0m 128 \n",
            "Q 940+858 T 1798 \u001b[91m☒\u001b[0m 1008\n",
            "Q 26+174  T 200  \u001b[91m☒\u001b[0m 122 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 2\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 17s 379us/step - loss: 1.7229 - acc: 0.3629 - val_loss: 1.6352 - val_acc: 0.3899\n",
            "Q 255+33  T 288  \u001b[91m☒\u001b[0m 559 \n",
            "Q 280+71  T 351  \u001b[91m☒\u001b[0m 209 \n",
            "Q 742+32  T 774  \u001b[91m☒\u001b[0m 408 \n",
            "Q 479+5   T 484  \u001b[91m☒\u001b[0m 105 \n",
            "Q 606+45  T 651  \u001b[91m☒\u001b[0m 605 \n",
            "Q 512+709 T 1221 \u001b[91m☒\u001b[0m 100 \n",
            "Q 93+19   T 112  \u001b[91m☒\u001b[0m 100 \n",
            "Q 395+335 T 730  \u001b[91m☒\u001b[0m 908 \n",
            "Q 881+859 T 1740 \u001b[91m☒\u001b[0m 1588\n",
            "Q 166+597 T 763  \u001b[91m☒\u001b[0m 100 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 3\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 18s 392us/step - loss: 1.5616 - acc: 0.4135 - val_loss: 1.4879 - val_acc: 0.4401\n",
            "Q 71+827  T 898  \u001b[91m☒\u001b[0m 897 \n",
            "Q 214+1   T 215  \u001b[91m☒\u001b[0m 224 \n",
            "Q 997+202 T 1199 \u001b[91m☒\u001b[0m 1101\n",
            "Q 370+11  T 381  \u001b[91m☒\u001b[0m 333 \n",
            "Q 923+890 T 1813 \u001b[91m☒\u001b[0m 1505\n",
            "Q 752+62  T 814  \u001b[91m☒\u001b[0m 735 \n",
            "Q 727+770 T 1497 \u001b[91m☒\u001b[0m 1407\n",
            "Q 4+817   T 821  \u001b[91m☒\u001b[0m 110 \n",
            "Q 29+292  T 321  \u001b[91m☒\u001b[0m 233 \n",
            "Q 94+249  T 343  \u001b[91m☒\u001b[0m 404 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 4\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 17s 382us/step - loss: 1.3959 - acc: 0.4803 - val_loss: 1.3116 - val_acc: 0.5136\n",
            "Q 904+41  T 945  \u001b[91m☒\u001b[0m 900 \n",
            "Q 730+94  T 824  \u001b[91m☒\u001b[0m 870 \n",
            "Q 634+19  T 653  \u001b[91m☒\u001b[0m 647 \n",
            "Q 34+878  T 912  \u001b[91m☒\u001b[0m 930 \n",
            "Q 43+327  T 370  \u001b[91m☒\u001b[0m 377 \n",
            "Q 93+405  T 498  \u001b[91m☒\u001b[0m 412 \n",
            "Q 399+19  T 418  \u001b[91m☒\u001b[0m 311 \n",
            "Q 35+743  T 778  \u001b[91m☒\u001b[0m 700 \n",
            "Q 176+74  T 250  \u001b[91m☒\u001b[0m 281 \n",
            "Q 449+700 T 1149 \u001b[91m☒\u001b[0m 1100\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 5\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 17s 379us/step - loss: 1.2472 - acc: 0.5374 - val_loss: 1.1895 - val_acc: 0.5567\n",
            "Q 76+865  T 941  \u001b[91m☒\u001b[0m 951 \n",
            "Q 7+149   T 156  \u001b[91m☒\u001b[0m 171 \n",
            "Q 97+121  T 218  \u001b[91m☒\u001b[0m 201 \n",
            "Q 809+21  T 830  \u001b[91m☒\u001b[0m 852 \n",
            "Q 644+1   T 645  \u001b[91m☒\u001b[0m 647 \n",
            "Q 461+59  T 520  \u001b[91m☒\u001b[0m 511 \n",
            "Q 71+51   T 122  \u001b[91m☒\u001b[0m 117 \n",
            "Q 573+996 T 1569 \u001b[91m☒\u001b[0m 1542\n",
            "Q 58+731  T 789  \u001b[91m☒\u001b[0m 715 \n",
            "Q 53+4    T 57   \u001b[91m☒\u001b[0m 50  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 6\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 17s 378us/step - loss: 1.1313 - acc: 0.5825 - val_loss: 1.0926 - val_acc: 0.5913\n",
            "Q 90+14   T 104  \u001b[91m☒\u001b[0m 110 \n",
            "Q 91+988  T 1079 \u001b[91m☒\u001b[0m 1060\n",
            "Q 275+99  T 374  \u001b[91m☒\u001b[0m 366 \n",
            "Q 30+676  T 706  \u001b[91m☒\u001b[0m 716 \n",
            "Q 654+2   T 656  \u001b[91m☒\u001b[0m 666 \n",
            "Q 990+33  T 1023 \u001b[91m☒\u001b[0m 1020\n",
            "Q 18+54   T 72   \u001b[91m☒\u001b[0m 80  \n",
            "Q 458+2   T 460  \u001b[91m☒\u001b[0m 566 \n",
            "Q 181+400 T 581  \u001b[91m☒\u001b[0m 561 \n",
            "Q 692+956 T 1648 \u001b[91m☒\u001b[0m 1622\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 7\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 17s 388us/step - loss: 1.0311 - acc: 0.6225 - val_loss: 0.9910 - val_acc: 0.6364\n",
            "Q 478+504 T 982  \u001b[91m☒\u001b[0m 900 \n",
            "Q 3+170   T 173  \u001b[91m☒\u001b[0m 170 \n",
            "Q 27+54   T 81   \u001b[91m☒\u001b[0m 80  \n",
            "Q 874+15  T 889  \u001b[91m☒\u001b[0m 887 \n",
            "Q 190+6   T 196  \u001b[91m☒\u001b[0m 191 \n",
            "Q 89+75   T 164  \u001b[91m☒\u001b[0m 154 \n",
            "Q 344+39  T 383  \u001b[91m☒\u001b[0m 386 \n",
            "Q 866+851 T 1717 \u001b[91m☒\u001b[0m 1722\n",
            "Q 3+956   T 959  \u001b[91m☒\u001b[0m 957 \n",
            "Q 417+44  T 461  \u001b[91m☒\u001b[0m 467 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 8\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 17s 378us/step - loss: 0.9496 - acc: 0.6577 - val_loss: 0.9203 - val_acc: 0.6664\n",
            "Q 35+88   T 123  \u001b[91m☒\u001b[0m 122 \n",
            "Q 18+243  T 261  \u001b[91m☒\u001b[0m 267 \n",
            "Q 541+12  T 553  \u001b[91m☒\u001b[0m 558 \n",
            "Q 654+824 T 1478 \u001b[91m☒\u001b[0m 1475\n",
            "Q 551+14  T 565  \u001b[91m☒\u001b[0m 567 \n",
            "Q 867+91  T 958  \u001b[91m☒\u001b[0m 953 \n",
            "Q 129+68  T 197  \u001b[91m☒\u001b[0m 293 \n",
            "Q 378+49  T 427  \u001b[91m☒\u001b[0m 425 \n",
            "Q 586+214 T 800  \u001b[91m☒\u001b[0m 898 \n",
            "Q 600+823 T 1423 \u001b[91m☒\u001b[0m 1435\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 9\n",
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 17s 379us/step - loss: 0.8762 - acc: 0.6852 - val_loss: 0.8581 - val_acc: 0.6842\n",
            "Q 39+278  T 317  \u001b[91m☒\u001b[0m 316 \n",
            "Q 567+59  T 626  \u001b[91m☒\u001b[0m 622 \n",
            "Q 72+554  T 626  \u001b[91m☒\u001b[0m 621 \n",
            "Q 913+38  T 951  \u001b[91m☒\u001b[0m 952 \n",
            "Q 610+210 T 820  \u001b[91m☒\u001b[0m 931 \n",
            "Q 5+251   T 256  \u001b[91m☒\u001b[0m 251 \n",
            "Q 118+883 T 1001 \u001b[91m☒\u001b[0m 1013\n",
            "Q 416+6   T 422  \u001b[92m☑\u001b[0m 422 \n",
            "Q 52+493  T 545  \u001b[91m☒\u001b[0m 541 \n",
            "Q 22+57   T 79   \u001b[91m☒\u001b[0m 83  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LvJowAxI9yDk",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TcdKT_jbFfRZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Creating the dataset"
      ]
    },
    {
      "metadata": {
        "id": "k6nCcyvntESH",
        "colab_type": "code",
        "outputId": "b30f883f-0762-40bc-ddc2-b68960497da4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        }
      },
      "cell_type": "code",
      "source": [
        "import random as r\n",
        "\n",
        "#first random data (One Huge break)\n",
        "length = 400\n",
        "n = r.randint(1,length+1)\n",
        "#n = np.random.random_integers(1, length)\n",
        "print(n)\n",
        "l1 = np.random.uniform(0,5,n)\n",
        "l2 = np.random.uniform(10,15,length-n)\n",
        "numbers = [*l1, *l2]\n",
        "plt.plot(numbers)\n",
        "plt.show()\n",
        "\n",
        "#Second random data (One smaller break)\n",
        "n = r.randint(1,length+1)\n",
        "print(n)\n",
        "l1 = np.random.uniform(0,5,n)\n",
        "l2 = np.random.uniform(5,15,length-n)\n",
        "numbers = [*l1, *l2]\n",
        "plt.plot(numbers)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "346\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-f9cf7ffa7eed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#n = np.random.random_integers(1, length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0ml2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mnumbers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "U_2-D5zFzHcn",
        "colab_type": "code",
        "outputId": "bc6138b2-e2b8-47e8-cd47-997a83607a6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "cell_type": "code",
      "source": [
        "###Setting the dataset \n",
        "\n",
        "length = 1000 #defining the number of datapoints in the set\n",
        "iterations = 10 #changing the number of iterations. not to high please \n",
        "\n",
        "master_data = []\n",
        "master_breaks = []\n",
        "\n",
        "#I ran into a problem of the set of breaks was not in sense of time but \n",
        "#just number of datapoints in that set \n",
        "def add_one_by_one(l):\n",
        "    new_l = []\n",
        "    cumsum = 0\n",
        "    for elt in l:\n",
        "        cumsum += elt\n",
        "        new_l.append(cumsum)\n",
        "    return new_l\n",
        "\n",
        "#creating the data. 1-10 breaks for each iteration \n",
        "for x in range(iterations):\n",
        "  for y in range(10):\n",
        "    num_of_breaks = y+1\n",
        "  \n",
        "    s=[]\n",
        "    for x in range(num_of_breaks):\n",
        "      s.append( r.randint(1,round(length/(num_of_breaks))))\n",
        "    s.append(length-sum(s)) #making sure the data is the right length\n",
        "\n",
        "    numbers = []\n",
        "    for x in range(num_of_breaks+1):\n",
        "      #every other set should have 0-5 and 5-10 datapoint values\n",
        "      if(x%2 == 0):\n",
        "        l = np.random.uniform(0,5,s[x]) \n",
        "      else:\n",
        "        l = np.random.uniform(5,10,s[x]) \n",
        "      numbers = numbers + [*l]\n",
        "    master_data.append(numbers) #saving that dataset\n",
        "    breaks = add_one_by_one(s) #changing the breakpoints\n",
        "    master_breaks.append(breaks) #saving the breakpoints \n",
        "\n",
        "#testing my creation     \n",
        "plt.plot(master_data[1])\n",
        "master_breaks[1]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7a72e2c9d54c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_of_breaks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m       \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_of_breaks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#making sure the data is the right length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'r' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "4Os4Xn3BFcpt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e8BIZBAUx34m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3fGeNNVXAVCP",
        "colab_type": "code",
        "outputId": "9c6335cb-ddea-458f-c0e7-233ab33c23ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "l=[1,2,3,4]\n",
        "\n",
        "def add_one_by_one(l):\n",
        "    new_l = []\n",
        "    cumsum = 0\n",
        "    for elt in l:\n",
        "        cumsum += elt\n",
        "        new_l.append(cumsum)\n",
        "    return new_l\n",
        "  \n",
        "add_one_by_one(l)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 3, 6, 10]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 252
        }
      ]
    }
  ]
}